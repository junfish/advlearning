{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvaQMRercMys",
        "outputId": "60747502-9b89-4d39-98e3-4bf42380f842"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BgE7XNPcw3m",
        "outputId": "178760cb-ef39-474c-f2e2-f3c265637a4f"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/CSE-498/Adversarial_Learning\n",
        "!ls\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/CSE-498/Adversarial_Learning\n",
            "attacking_main.py  datasets\t\t   Middle_Results  README.md\n",
            "base_model.py\t   experiment_operator.py  model_weights   run_code.ipynb\n",
            "data_process.py    learning_main.py\t   __pycache__\n",
            "Sun Mar 21 08:55:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "927gAao0NbFv",
        "outputId": "d56e67d8-2fd5-4314-a513-37352d2341e5"
      },
      "source": [
        "!python attacking_teset.py 1 1 -l 1e-1 -n 1 -b 1 -p "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cifar10 to the memory...\n",
            "Initialize ResNet18...\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x563971c06000 @  0x7ff8602c51e7 0x7ff80c11b46e 0x7ff80c16bc7b 0x7ff80c16bebe 0x7ff80c204887 0x56395a04f050 0x56395a14099d 0x56395a0c2fe9 0x56395a05069a 0x56395a0bec9e 0x56395a0bdb0e 0x56395a0bd813 0x56395a187592 0x56395a18790d 0x56395a1877b6 0x56395a15f103 0x56395a15edac 0x7ff85f0afbf7 0x56395a15ec8a\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x563971c06000 @  0x7ff8602c51e7 0x7ff80c11b46e 0x7ff80c16bc7b 0x7ff80c16bebe 0x7ff80c204887 0x56395a04f050 0x56395a14099d 0x56395a0c2fe9 0x56395a05069a 0x56395a0bec9e 0x56395a0bdb0e 0x56395a0bd813 0x56395a187592 0x56395a18790d 0x56395a1877b6 0x56395a15f103 0x56395a15edac 0x7ff85f0afbf7 0x56395a15ec8a\n",
            "Loading learned parameters...\n",
            "Print model's performance: training_accuracy = 0.9986, testing_accuracy = 0.9058\n",
            "                           training_loss = 0.005683, testing_loss = 0.600583\n",
            "0.8181\n",
            "0.7431\n",
            "0.7258\n",
            "0.7213\n",
            "0.7211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8w4dsHzqiap7",
        "outputId": "8f9fbb67-92a2-472d-daea-7dbb09c6fc20"
      },
      "source": [
        "# 226 426 912 1034\n",
        "# model dataset --lr --norm --batch_size --sample --pgd(action=\"store_true\") --target \n",
        "%run attacking_main.py 1 1 -l 1e-1 -n 1 -b 100 -s 30"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cifar10 to the memory...\n",
            "Initialize ResNet18...\n",
            "The chosen picture's idx and class are as below:\n",
            "6\n",
            "frog\n",
            "Visualize this picture:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loading learned parameters...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Print model's performance: training_accuracy = 0.9988, testing_accuracy = 0.9058\n",
            "                           training_loss = 0.000056, testing_loss = 0.006006\n",
            "Prediction before attack:\n",
            "True class probability: 1.0\n",
            "Predictive class: 6\n",
            "Start attacking...\n",
            "After perturbation:\n",
            "True class probability: 8.883269401849248e-06\n",
            "Predictive class: 3\n",
            "Highest class probability: 0.9999819993972778\n",
            "Visualization of sign(gradient):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Visualization of perturbed sample:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRRT0_7thzfR",
        "outputId": "b2873269-4934-439e-f086-cd53ddcaf6fd"
      },
      "source": [
        "!python learning_main.py --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: learning_main.py [-h] [-l LR] [-n NORM] [-b BATCH_SIZE] [-i ITERATIONS]\n",
            "                        [-s SCHEDULE_INTERVALS [SCHEDULE_INTERVALS ...]]\n",
            "                        {0,1} {0,1}\n",
            "\n",
            "This is the main training program.\n",
            "Firstly, You can specify the dataset and network for the learning process.\n",
            "Secondly, You can also set hyper-parameters for your model training.\n",
            "More details can be seen from the introduction of arguments below .\n",
            "\n",
            "positional arguments:\n",
            "  {0,1}                 specify a deep learning model (1 as default)\n",
            "                        0: LeNet (a CNN with two conv layers)\n",
            "                        1: ResNet18 (change the first conv layer a little bit)\n",
            "  {0,1}                 specify a dataset to learn (1 as default)\n",
            "                        0: mnist\n",
            "                        1: cifar10\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -l LR, --lr LR        give an initial learning rate to our model\n",
            "  -n NORM, --norm NORM  choose the norm for normalization\n",
            "                        0: imagenet mean and std\n",
            "                        1: compute own mean and std\n",
            "  -b BATCH_SIZE, --batch_size BATCH_SIZE\n",
            "                        set a batch size for the training and testing process\n",
            "  -i ITERATIONS, --iterations ITERATIONS\n",
            "                        the total number of epoch for the training\n",
            "  -s SCHEDULE_INTERVALS [SCHEDULE_INTERVALS ...], --schedule_intervals SCHEDULE_INTERVALS [SCHEDULE_INTERVALS ...]\n",
            "                        intervals to degrade learning rate\n",
            "                        e.x., recommendation: start at lr = 0.1, intervals = [135, 230, 300], divided by 10, for cifar10 & resnet18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqLvIaTGc71t",
        "outputId": "1feaf7a1-f149-45f0-afeb-abd7d9631a14"
      },
      "source": [
        "# model dataset --lr --norm --batch_size --iterations --schedule_intervals\n",
        "!python learning_main.py 1 1 -l 0.1 -n 1 -b 100 -i 400 -s 135 230 300"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=100, dataset=1, iterations=400, lr=0.1, model=1, norm=1, schedule_intervals=[135, 230, 300])\n",
            "Loading cifar10 to the memory.\n",
            "Initializing ResNet18...\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x556eb1c0c000 @  0x7f502fde01e7 0x7f4fdbc3646e 0x7f4fdbc86c7b 0x7f4fdbc86ebe 0x7f4fdbd1f887 0x556e98c70050 0x556e98d6199d 0x556e98ce3fe9 0x556e98c7169a 0x556e98cdfc9e 0x556e98cdeb0e 0x556e98cde813 0x556e98da8592 0x556e98da890d 0x556e98da87b6 0x556e98d80103 0x556e98d7fdac 0x7f502ebcabf7 0x556e98d7fc8a\n",
            "tcmalloc: large alloc 1228800000 bytes == 0x556eb1c0c000 @  0x7f502fde01e7 0x7f4fdbc3646e 0x7f4fdbc86c7b 0x7f4fdbc86ebe 0x7f4fdbd1f887 0x556e98c70050 0x556e98d6199d 0x556e98ce3fe9 0x556e98c7169a 0x556e98cdfc9e 0x556e98cdeb0e 0x556e98cde813 0x556e98da8592 0x556e98da890d 0x556e98da87b6 0x556e98d80103 0x556e98d7fdac 0x7f502ebcabf7 0x556e98d7fc8a\n",
            "Start training...\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 001: training_accuracy = 0.4351, testing_accuracy = 0.4616\n",
            "           training_loss = 0.015250, testing_loss = 0.014672\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 002: training_accuracy = 0.5145, testing_accuracy = 0.5361\n",
            "           training_loss = 0.013434, testing_loss = 0.012830\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 003: training_accuracy = 0.5875, testing_accuracy = 0.6035\n",
            "           training_loss = 0.011441, testing_loss = 0.010920\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 004: training_accuracy = 0.6134, testing_accuracy = 0.6260\n",
            "           training_loss = 0.010863, testing_loss = 0.010566\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 005: training_accuracy = 0.6602, testing_accuracy = 0.6726\n",
            "           training_loss = 0.009529, testing_loss = 0.009239\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 006: training_accuracy = 0.6726, testing_accuracy = 0.6873\n",
            "           training_loss = 0.009326, testing_loss = 0.009093\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 007: training_accuracy = 0.6987, testing_accuracy = 0.7003\n",
            "           training_loss = 0.008663, testing_loss = 0.008685\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 008: training_accuracy = 0.7205, testing_accuracy = 0.7229\n",
            "           training_loss = 0.007864, testing_loss = 0.007734\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 009: training_accuracy = 0.6937, testing_accuracy = 0.6918\n",
            "           training_loss = 0.008848, testing_loss = 0.009136\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 010: training_accuracy = 0.7543, testing_accuracy = 0.7556\n",
            "           training_loss = 0.007000, testing_loss = 0.007134\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 011: training_accuracy = 0.7725, testing_accuracy = 0.7690\n",
            "           training_loss = 0.006456, testing_loss = 0.006648\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 012: training_accuracy = 0.7832, testing_accuracy = 0.7808\n",
            "           training_loss = 0.006147, testing_loss = 0.006447\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 013: training_accuracy = 0.7701, testing_accuracy = 0.7622\n",
            "           training_loss = 0.006516, testing_loss = 0.006857\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 014: training_accuracy = 0.7854, testing_accuracy = 0.7796\n",
            "           training_loss = 0.006180, testing_loss = 0.006477\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 015: training_accuracy = 0.7962, testing_accuracy = 0.7895\n",
            "           training_loss = 0.005906, testing_loss = 0.006180\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 016: training_accuracy = 0.7958, testing_accuracy = 0.7846\n",
            "           training_loss = 0.005896, testing_loss = 0.006145\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 017: training_accuracy = 0.8066, testing_accuracy = 0.7944\n",
            "           training_loss = 0.005634, testing_loss = 0.006154\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 018: training_accuracy = 0.8206, testing_accuracy = 0.8165\n",
            "           training_loss = 0.005160, testing_loss = 0.005511\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 019: training_accuracy = 0.8116, testing_accuracy = 0.8031\n",
            "           training_loss = 0.005440, testing_loss = 0.005895\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 020: training_accuracy = 0.8238, testing_accuracy = 0.8101\n",
            "           training_loss = 0.005065, testing_loss = 0.005641\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 021: training_accuracy = 0.8264, testing_accuracy = 0.8126\n",
            "           training_loss = 0.004967, testing_loss = 0.005473\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 022: training_accuracy = 0.8241, testing_accuracy = 0.8132\n",
            "           training_loss = 0.005034, testing_loss = 0.005528\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 023: training_accuracy = 0.8333, testing_accuracy = 0.8187\n",
            "           training_loss = 0.004958, testing_loss = 0.005341\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 024: training_accuracy = 0.8471, testing_accuracy = 0.8282\n",
            "           training_loss = 0.004456, testing_loss = 0.005097\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 025: training_accuracy = 0.8480, testing_accuracy = 0.8266\n",
            "           training_loss = 0.004536, testing_loss = 0.005142\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 027: training_accuracy = 0.8486, testing_accuracy = 0.8231\n",
            "           training_loss = 0.004460, testing_loss = 0.005113\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 028: training_accuracy = 0.8596, testing_accuracy = 0.8372\n",
            "           training_loss = 0.004032, testing_loss = 0.004860\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 029: training_accuracy = 0.8611, testing_accuracy = 0.8370\n",
            "           training_loss = 0.004071, testing_loss = 0.004887\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 030: training_accuracy = 0.8502, testing_accuracy = 0.8249\n",
            "           training_loss = 0.004428, testing_loss = 0.005172\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 031: training_accuracy = 0.8558, testing_accuracy = 0.8328\n",
            "           training_loss = 0.004209, testing_loss = 0.005096\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 032: training_accuracy = 0.8473, testing_accuracy = 0.8237\n",
            "           training_loss = 0.004434, testing_loss = 0.005343\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 033: training_accuracy = 0.8656, testing_accuracy = 0.8375\n",
            "           training_loss = 0.003938, testing_loss = 0.004877\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 034: training_accuracy = 0.8717, testing_accuracy = 0.8402\n",
            "           training_loss = 0.003742, testing_loss = 0.004773\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 035: training_accuracy = 0.8684, testing_accuracy = 0.8382\n",
            "           training_loss = 0.003826, testing_loss = 0.004716\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 036: training_accuracy = 0.8554, testing_accuracy = 0.8309\n",
            "           training_loss = 0.004155, testing_loss = 0.004985\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 037: training_accuracy = 0.8644, testing_accuracy = 0.8349\n",
            "           training_loss = 0.003939, testing_loss = 0.004903\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 038: training_accuracy = 0.8485, testing_accuracy = 0.8276\n",
            "           training_loss = 0.004342, testing_loss = 0.005136\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 039: training_accuracy = 0.8678, testing_accuracy = 0.8390\n",
            "           training_loss = 0.003805, testing_loss = 0.004781\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 040: training_accuracy = 0.8632, testing_accuracy = 0.8304\n",
            "           training_loss = 0.003924, testing_loss = 0.005096\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 041: training_accuracy = 0.8852, testing_accuracy = 0.8515\n",
            "           training_loss = 0.003322, testing_loss = 0.004499\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 042: training_accuracy = 0.8763, testing_accuracy = 0.8516\n",
            "           training_loss = 0.003586, testing_loss = 0.004491\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 043: training_accuracy = 0.8804, testing_accuracy = 0.8464\n",
            "           training_loss = 0.003465, testing_loss = 0.004688\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 044: training_accuracy = 0.8784, testing_accuracy = 0.8444\n",
            "           training_loss = 0.003520, testing_loss = 0.004670\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 045: training_accuracy = 0.8725, testing_accuracy = 0.8431\n",
            "           training_loss = 0.003654, testing_loss = 0.004657\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 046: training_accuracy = 0.8772, testing_accuracy = 0.8435\n",
            "           training_loss = 0.003574, testing_loss = 0.004819\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 047: training_accuracy = 0.8734, testing_accuracy = 0.8430\n",
            "           training_loss = 0.003677, testing_loss = 0.004665\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 048: training_accuracy = 0.8820, testing_accuracy = 0.8494\n",
            "           training_loss = 0.003407, testing_loss = 0.004634\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 049: training_accuracy = 0.8810, testing_accuracy = 0.8474\n",
            "           training_loss = 0.003519, testing_loss = 0.004445\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 050: training_accuracy = 0.8740, testing_accuracy = 0.8425\n",
            "           training_loss = 0.003665, testing_loss = 0.004730\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 051: training_accuracy = 0.8930, testing_accuracy = 0.8565\n",
            "           training_loss = 0.003129, testing_loss = 0.004488\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 052: training_accuracy = 0.8859, testing_accuracy = 0.8489\n",
            "           training_loss = 0.003288, testing_loss = 0.004599\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 053: training_accuracy = 0.8842, testing_accuracy = 0.8474\n",
            "           training_loss = 0.003394, testing_loss = 0.004678\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 054: training_accuracy = 0.8655, testing_accuracy = 0.8390\n",
            "           training_loss = 0.003879, testing_loss = 0.004764\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 055: training_accuracy = 0.8921, testing_accuracy = 0.8559\n",
            "           training_loss = 0.003173, testing_loss = 0.004499\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 056: training_accuracy = 0.8914, testing_accuracy = 0.8553\n",
            "           training_loss = 0.003145, testing_loss = 0.004565\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 057: training_accuracy = 0.8556, testing_accuracy = 0.8275\n",
            "           training_loss = 0.004177, testing_loss = 0.005228\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 058: training_accuracy = 0.8855, testing_accuracy = 0.8492\n",
            "           training_loss = 0.003295, testing_loss = 0.004671\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 059: training_accuracy = 0.8868, testing_accuracy = 0.8446\n",
            "           training_loss = 0.003286, testing_loss = 0.004724\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 060: training_accuracy = 0.8746, testing_accuracy = 0.8474\n",
            "           training_loss = 0.003646, testing_loss = 0.004808\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 061: training_accuracy = 0.8819, testing_accuracy = 0.8482\n",
            "           training_loss = 0.003415, testing_loss = 0.004655\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 062: training_accuracy = 0.8676, testing_accuracy = 0.8325\n",
            "           training_loss = 0.003849, testing_loss = 0.005272\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 063: training_accuracy = 0.8889, testing_accuracy = 0.8562\n",
            "           training_loss = 0.003194, testing_loss = 0.004701\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 064: training_accuracy = 0.8941, testing_accuracy = 0.8562\n",
            "           training_loss = 0.003114, testing_loss = 0.004359\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 065: training_accuracy = 0.8877, testing_accuracy = 0.8487\n",
            "           training_loss = 0.003242, testing_loss = 0.004547\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 066: training_accuracy = 0.8995, testing_accuracy = 0.8618\n",
            "           training_loss = 0.002935, testing_loss = 0.004282\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 067: training_accuracy = 0.8942, testing_accuracy = 0.8550\n",
            "           training_loss = 0.003003, testing_loss = 0.004314\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 068: training_accuracy = 0.8928, testing_accuracy = 0.8553\n",
            "           training_loss = 0.003096, testing_loss = 0.004363\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 069: training_accuracy = 0.8784, testing_accuracy = 0.8477\n",
            "           training_loss = 0.003520, testing_loss = 0.004833\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 070: training_accuracy = 0.8748, testing_accuracy = 0.8425\n",
            "           training_loss = 0.003591, testing_loss = 0.004808\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 071: training_accuracy = 0.8994, testing_accuracy = 0.8607\n",
            "           training_loss = 0.002941, testing_loss = 0.004399\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 072: training_accuracy = 0.8897, testing_accuracy = 0.8507\n",
            "           training_loss = 0.003166, testing_loss = 0.004600\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 073: training_accuracy = 0.9011, testing_accuracy = 0.8603\n",
            "           training_loss = 0.002857, testing_loss = 0.004232\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 074: training_accuracy = 0.8951, testing_accuracy = 0.8578\n",
            "           training_loss = 0.003042, testing_loss = 0.004395\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 075: training_accuracy = 0.8853, testing_accuracy = 0.8439\n",
            "           training_loss = 0.003299, testing_loss = 0.004763\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 076: training_accuracy = 0.9057, testing_accuracy = 0.8654\n",
            "           training_loss = 0.002769, testing_loss = 0.004254\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 077: training_accuracy = 0.8920, testing_accuracy = 0.8474\n",
            "           training_loss = 0.003116, testing_loss = 0.004601\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 078: training_accuracy = 0.8951, testing_accuracy = 0.8637\n",
            "           training_loss = 0.003080, testing_loss = 0.004135\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 079: training_accuracy = 0.8910, testing_accuracy = 0.8463\n",
            "           training_loss = 0.003219, testing_loss = 0.004746\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 080: training_accuracy = 0.9025, testing_accuracy = 0.8636\n",
            "           training_loss = 0.002841, testing_loss = 0.004268\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 081: training_accuracy = 0.9023, testing_accuracy = 0.8660\n",
            "           training_loss = 0.002838, testing_loss = 0.004240\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 082: training_accuracy = 0.9035, testing_accuracy = 0.8601\n",
            "           training_loss = 0.002811, testing_loss = 0.004289\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 083: training_accuracy = 0.9150, testing_accuracy = 0.8729\n",
            "           training_loss = 0.002464, testing_loss = 0.003999\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 084: training_accuracy = 0.9096, testing_accuracy = 0.8625\n",
            "           training_loss = 0.002676, testing_loss = 0.004124\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 085: training_accuracy = 0.9064, testing_accuracy = 0.8632\n",
            "           training_loss = 0.002789, testing_loss = 0.004111\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 086: training_accuracy = 0.9070, testing_accuracy = 0.8669\n",
            "           training_loss = 0.002710, testing_loss = 0.004054\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 087: training_accuracy = 0.9130, testing_accuracy = 0.8703\n",
            "           training_loss = 0.002531, testing_loss = 0.004100\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 088: training_accuracy = 0.9024, testing_accuracy = 0.8609\n",
            "           training_loss = 0.002846, testing_loss = 0.004216\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 089: training_accuracy = 0.9085, testing_accuracy = 0.8674\n",
            "           training_loss = 0.002663, testing_loss = 0.004216\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 090: training_accuracy = 0.9033, testing_accuracy = 0.8607\n",
            "           training_loss = 0.002839, testing_loss = 0.004308\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 091: training_accuracy = 0.9051, testing_accuracy = 0.8604\n",
            "           training_loss = 0.002786, testing_loss = 0.004212\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 092: training_accuracy = 0.9048, testing_accuracy = 0.8582\n",
            "           training_loss = 0.002799, testing_loss = 0.004300\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 093: training_accuracy = 0.9001, testing_accuracy = 0.8610\n",
            "           training_loss = 0.002890, testing_loss = 0.004389\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 094: training_accuracy = 0.8893, testing_accuracy = 0.8544\n",
            "           training_loss = 0.003248, testing_loss = 0.004599\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 095: training_accuracy = 0.9057, testing_accuracy = 0.8653\n",
            "           training_loss = 0.002699, testing_loss = 0.004249\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 096: training_accuracy = 0.9079, testing_accuracy = 0.8622\n",
            "           training_loss = 0.002715, testing_loss = 0.004197\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 097: training_accuracy = 0.9125, testing_accuracy = 0.8660\n",
            "           training_loss = 0.002558, testing_loss = 0.004250\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 098: training_accuracy = 0.9088, testing_accuracy = 0.8637\n",
            "           training_loss = 0.002628, testing_loss = 0.004283\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 099: training_accuracy = 0.9144, testing_accuracy = 0.8717\n",
            "           training_loss = 0.002466, testing_loss = 0.004154\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 100: training_accuracy = 0.9053, testing_accuracy = 0.8548\n",
            "           training_loss = 0.002729, testing_loss = 0.004482\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 101: training_accuracy = 0.9078, testing_accuracy = 0.8626\n",
            "           training_loss = 0.002668, testing_loss = 0.004408\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 102: training_accuracy = 0.9160, testing_accuracy = 0.8711\n",
            "           training_loss = 0.002464, testing_loss = 0.003927\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 103: training_accuracy = 0.9196, testing_accuracy = 0.8714\n",
            "           training_loss = 0.002373, testing_loss = 0.004236\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 104: training_accuracy = 0.9042, testing_accuracy = 0.8619\n",
            "           training_loss = 0.002774, testing_loss = 0.004630\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 105: training_accuracy = 0.9005, testing_accuracy = 0.8524\n",
            "           training_loss = 0.002912, testing_loss = 0.004657\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 106: training_accuracy = 0.9036, testing_accuracy = 0.8574\n",
            "           training_loss = 0.002773, testing_loss = 0.004563\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 107: training_accuracy = 0.9076, testing_accuracy = 0.8657\n",
            "           training_loss = 0.002726, testing_loss = 0.004110\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 108: training_accuracy = 0.8989, testing_accuracy = 0.8570\n",
            "           training_loss = 0.002871, testing_loss = 0.004409\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 109: training_accuracy = 0.9128, testing_accuracy = 0.8623\n",
            "           training_loss = 0.002536, testing_loss = 0.004497\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 110: training_accuracy = 0.9067, testing_accuracy = 0.8597\n",
            "           training_loss = 0.002710, testing_loss = 0.004275\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 111: training_accuracy = 0.9105, testing_accuracy = 0.8677\n",
            "           training_loss = 0.002573, testing_loss = 0.004229\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 112: training_accuracy = 0.9198, testing_accuracy = 0.8751\n",
            "           training_loss = 0.002360, testing_loss = 0.003916\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 113: training_accuracy = 0.9018, testing_accuracy = 0.8546\n",
            "           training_loss = 0.002816, testing_loss = 0.004538\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 114: training_accuracy = 0.9120, testing_accuracy = 0.8692\n",
            "           training_loss = 0.002572, testing_loss = 0.004082\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 115: training_accuracy = 0.8967, testing_accuracy = 0.8433\n",
            "           training_loss = 0.002993, testing_loss = 0.004669\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 116: training_accuracy = 0.9051, testing_accuracy = 0.8552\n",
            "           training_loss = 0.002808, testing_loss = 0.004576\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 117: training_accuracy = 0.9160, testing_accuracy = 0.8686\n",
            "           training_loss = 0.002473, testing_loss = 0.004190\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 118: training_accuracy = 0.9081, testing_accuracy = 0.8676\n",
            "           training_loss = 0.002664, testing_loss = 0.004283\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 119: training_accuracy = 0.9054, testing_accuracy = 0.8630\n",
            "           training_loss = 0.002817, testing_loss = 0.004377\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 120: training_accuracy = 0.9017, testing_accuracy = 0.8550\n",
            "           training_loss = 0.002900, testing_loss = 0.004757\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 121: training_accuracy = 0.9153, testing_accuracy = 0.8660\n",
            "           training_loss = 0.002465, testing_loss = 0.004244\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 122: training_accuracy = 0.9074, testing_accuracy = 0.8612\n",
            "           training_loss = 0.002663, testing_loss = 0.004288\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 123: training_accuracy = 0.9026, testing_accuracy = 0.8613\n",
            "           training_loss = 0.002812, testing_loss = 0.004378\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 124: training_accuracy = 0.9087, testing_accuracy = 0.8649\n",
            "           training_loss = 0.002664, testing_loss = 0.004389\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 125: training_accuracy = 0.8957, testing_accuracy = 0.8502\n",
            "           training_loss = 0.003034, testing_loss = 0.004945\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 126: training_accuracy = 0.9210, testing_accuracy = 0.8707\n",
            "           training_loss = 0.002291, testing_loss = 0.003964\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 127: training_accuracy = 0.9121, testing_accuracy = 0.8647\n",
            "           training_loss = 0.002536, testing_loss = 0.004282\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 128: training_accuracy = 0.9208, testing_accuracy = 0.8686\n",
            "           training_loss = 0.002294, testing_loss = 0.004040\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 129: training_accuracy = 0.9131, testing_accuracy = 0.8679\n",
            "           training_loss = 0.002519, testing_loss = 0.004346\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 130: training_accuracy = 0.9156, testing_accuracy = 0.8697\n",
            "           training_loss = 0.002445, testing_loss = 0.004110\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 131: training_accuracy = 0.9157, testing_accuracy = 0.8707\n",
            "           training_loss = 0.002460, testing_loss = 0.004024\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 132: training_accuracy = 0.9182, testing_accuracy = 0.8738\n",
            "           training_loss = 0.002361, testing_loss = 0.004108\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 133: training_accuracy = 0.9152, testing_accuracy = 0.8659\n",
            "           training_loss = 0.002499, testing_loss = 0.004232\n",
            "Learning Rate = 0.10000000\n",
            "Epoch 134: training_accuracy = 0.9042, testing_accuracy = 0.8570\n",
            "           training_loss = 0.002740, testing_loss = 0.004621\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 135: training_accuracy = 0.9096, testing_accuracy = 0.8658\n",
            "           training_loss = 0.002639, testing_loss = 0.004161\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 136: training_accuracy = 0.9566, testing_accuracy = 0.8986\n",
            "           training_loss = 0.001264, testing_loss = 0.003472\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 137: training_accuracy = 0.9595, testing_accuracy = 0.8990\n",
            "           training_loss = 0.001174, testing_loss = 0.003522\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 138: training_accuracy = 0.9625, testing_accuracy = 0.8983\n",
            "           training_loss = 0.001071, testing_loss = 0.003473\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 139: training_accuracy = 0.9657, testing_accuracy = 0.9001\n",
            "           training_loss = 0.000987, testing_loss = 0.003584\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 140: training_accuracy = 0.9672, testing_accuracy = 0.9018\n",
            "           training_loss = 0.000966, testing_loss = 0.003537\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 141: training_accuracy = 0.9690, testing_accuracy = 0.9035\n",
            "           training_loss = 0.000884, testing_loss = 0.003543\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 142: training_accuracy = 0.9691, testing_accuracy = 0.9021\n",
            "           training_loss = 0.000901, testing_loss = 0.003610\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 143: training_accuracy = 0.9705, testing_accuracy = 0.9026\n",
            "           training_loss = 0.000857, testing_loss = 0.003675\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 144: training_accuracy = 0.9716, testing_accuracy = 0.9017\n",
            "           training_loss = 0.000815, testing_loss = 0.003649\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 145: training_accuracy = 0.9722, testing_accuracy = 0.9029\n",
            "           training_loss = 0.000812, testing_loss = 0.003746\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 146: training_accuracy = 0.9749, testing_accuracy = 0.9032\n",
            "           training_loss = 0.000721, testing_loss = 0.003688\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 147: training_accuracy = 0.9733, testing_accuracy = 0.9052\n",
            "           training_loss = 0.000774, testing_loss = 0.003814\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 148: training_accuracy = 0.9748, testing_accuracy = 0.9028\n",
            "           training_loss = 0.000744, testing_loss = 0.003770\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 149: training_accuracy = 0.9757, testing_accuracy = 0.9029\n",
            "           training_loss = 0.000705, testing_loss = 0.003855\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 150: training_accuracy = 0.9765, testing_accuracy = 0.9001\n",
            "           training_loss = 0.000680, testing_loss = 0.003836\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 151: training_accuracy = 0.9766, testing_accuracy = 0.9013\n",
            "           training_loss = 0.000686, testing_loss = 0.003920\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 152: training_accuracy = 0.9753, testing_accuracy = 0.9024\n",
            "           training_loss = 0.000699, testing_loss = 0.004079\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 153: training_accuracy = 0.9775, testing_accuracy = 0.9029\n",
            "           training_loss = 0.000649, testing_loss = 0.003964\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 154: training_accuracy = 0.9791, testing_accuracy = 0.9007\n",
            "           training_loss = 0.000612, testing_loss = 0.004022\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 155: training_accuracy = 0.9792, testing_accuracy = 0.9030\n",
            "           training_loss = 0.000607, testing_loss = 0.003867\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 156: training_accuracy = 0.9806, testing_accuracy = 0.9027\n",
            "           training_loss = 0.000559, testing_loss = 0.004029\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 157: training_accuracy = 0.9773, testing_accuracy = 0.9002\n",
            "           training_loss = 0.000646, testing_loss = 0.004148\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 158: training_accuracy = 0.9809, testing_accuracy = 0.9020\n",
            "           training_loss = 0.000551, testing_loss = 0.004163\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 159: training_accuracy = 0.9810, testing_accuracy = 0.9038\n",
            "           training_loss = 0.000538, testing_loss = 0.004193\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 160: training_accuracy = 0.9811, testing_accuracy = 0.9041\n",
            "           training_loss = 0.000556, testing_loss = 0.004259\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 161: training_accuracy = 0.9802, testing_accuracy = 0.9033\n",
            "           training_loss = 0.000569, testing_loss = 0.004291\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 162: training_accuracy = 0.9804, testing_accuracy = 0.9022\n",
            "           training_loss = 0.000570, testing_loss = 0.004336\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 163: training_accuracy = 0.9816, testing_accuracy = 0.9028\n",
            "           training_loss = 0.000524, testing_loss = 0.004183\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 164: training_accuracy = 0.9794, testing_accuracy = 0.8996\n",
            "           training_loss = 0.000580, testing_loss = 0.004490\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 165: training_accuracy = 0.9818, testing_accuracy = 0.9030\n",
            "           training_loss = 0.000521, testing_loss = 0.004335\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 166: training_accuracy = 0.9832, testing_accuracy = 0.9035\n",
            "           training_loss = 0.000475, testing_loss = 0.004233\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 167: training_accuracy = 0.9841, testing_accuracy = 0.9025\n",
            "           training_loss = 0.000457, testing_loss = 0.004264\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 168: training_accuracy = 0.9852, testing_accuracy = 0.9016\n",
            "           training_loss = 0.000443, testing_loss = 0.004258\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 169: training_accuracy = 0.9841, testing_accuracy = 0.9023\n",
            "           training_loss = 0.000467, testing_loss = 0.004352\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 170: training_accuracy = 0.9834, testing_accuracy = 0.9033\n",
            "           training_loss = 0.000460, testing_loss = 0.004525\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 171: training_accuracy = 0.9854, testing_accuracy = 0.9037\n",
            "           training_loss = 0.000425, testing_loss = 0.004332\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 172: training_accuracy = 0.9858, testing_accuracy = 0.9060\n",
            "           training_loss = 0.000413, testing_loss = 0.004232\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 173: training_accuracy = 0.9855, testing_accuracy = 0.9021\n",
            "           training_loss = 0.000423, testing_loss = 0.004528\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 174: training_accuracy = 0.9837, testing_accuracy = 0.9037\n",
            "           training_loss = 0.000472, testing_loss = 0.004587\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 175: training_accuracy = 0.9831, testing_accuracy = 0.9011\n",
            "           training_loss = 0.000470, testing_loss = 0.004753\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 176: training_accuracy = 0.9829, testing_accuracy = 0.9030\n",
            "           training_loss = 0.000478, testing_loss = 0.004583\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 177: training_accuracy = 0.9870, testing_accuracy = 0.9048\n",
            "           training_loss = 0.000380, testing_loss = 0.004535\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 178: training_accuracy = 0.9862, testing_accuracy = 0.9031\n",
            "           training_loss = 0.000407, testing_loss = 0.004714\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 179: training_accuracy = 0.9866, testing_accuracy = 0.9025\n",
            "           training_loss = 0.000391, testing_loss = 0.004619\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 180: training_accuracy = 0.9855, testing_accuracy = 0.9002\n",
            "           training_loss = 0.000424, testing_loss = 0.004658\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 181: training_accuracy = 0.9860, testing_accuracy = 0.9019\n",
            "           training_loss = 0.000410, testing_loss = 0.004615\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 182: training_accuracy = 0.9870, testing_accuracy = 0.9019\n",
            "           training_loss = 0.000378, testing_loss = 0.004596\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 183: training_accuracy = 0.9875, testing_accuracy = 0.9018\n",
            "           training_loss = 0.000367, testing_loss = 0.004675\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 184: training_accuracy = 0.9849, testing_accuracy = 0.9015\n",
            "           training_loss = 0.000439, testing_loss = 0.004851\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 185: training_accuracy = 0.9853, testing_accuracy = 0.9023\n",
            "           training_loss = 0.000417, testing_loss = 0.004801\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 186: training_accuracy = 0.9885, testing_accuracy = 0.9036\n",
            "           training_loss = 0.000358, testing_loss = 0.004617\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 187: training_accuracy = 0.9854, testing_accuracy = 0.8999\n",
            "           training_loss = 0.000424, testing_loss = 0.004989\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 188: training_accuracy = 0.9865, testing_accuracy = 0.9024\n",
            "           training_loss = 0.000381, testing_loss = 0.004763\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 189: training_accuracy = 0.9878, testing_accuracy = 0.9021\n",
            "           training_loss = 0.000354, testing_loss = 0.004857\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 190: training_accuracy = 0.9878, testing_accuracy = 0.9013\n",
            "           training_loss = 0.000369, testing_loss = 0.004779\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 191: training_accuracy = 0.9861, testing_accuracy = 0.8987\n",
            "           training_loss = 0.000384, testing_loss = 0.004810\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 192: training_accuracy = 0.9883, testing_accuracy = 0.9027\n",
            "           training_loss = 0.000341, testing_loss = 0.004641\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 193: training_accuracy = 0.9876, testing_accuracy = 0.9011\n",
            "           training_loss = 0.000356, testing_loss = 0.004839\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 194: training_accuracy = 0.9890, testing_accuracy = 0.9030\n",
            "           training_loss = 0.000332, testing_loss = 0.004745\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 195: training_accuracy = 0.9887, testing_accuracy = 0.9035\n",
            "           training_loss = 0.000338, testing_loss = 0.004635\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 196: training_accuracy = 0.9890, testing_accuracy = 0.9032\n",
            "           training_loss = 0.000317, testing_loss = 0.004823\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 197: training_accuracy = 0.9895, testing_accuracy = 0.8990\n",
            "           training_loss = 0.000318, testing_loss = 0.004806\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 198: training_accuracy = 0.9852, testing_accuracy = 0.8988\n",
            "           training_loss = 0.000414, testing_loss = 0.005111\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 199: training_accuracy = 0.9881, testing_accuracy = 0.8998\n",
            "           training_loss = 0.000352, testing_loss = 0.004928\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 200: training_accuracy = 0.9829, testing_accuracy = 0.8949\n",
            "           training_loss = 0.000473, testing_loss = 0.005116\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 201: training_accuracy = 0.9877, testing_accuracy = 0.9014\n",
            "           training_loss = 0.000361, testing_loss = 0.004872\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 202: training_accuracy = 0.9882, testing_accuracy = 0.9017\n",
            "           training_loss = 0.000352, testing_loss = 0.004823\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 203: training_accuracy = 0.9858, testing_accuracy = 0.8979\n",
            "           training_loss = 0.000406, testing_loss = 0.005198\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 204: training_accuracy = 0.9877, testing_accuracy = 0.8995\n",
            "           training_loss = 0.000357, testing_loss = 0.004909\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 205: training_accuracy = 0.9879, testing_accuracy = 0.9010\n",
            "           training_loss = 0.000338, testing_loss = 0.004981\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 206: training_accuracy = 0.9888, testing_accuracy = 0.9021\n",
            "           training_loss = 0.000328, testing_loss = 0.005017\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 207: training_accuracy = 0.9846, testing_accuracy = 0.8970\n",
            "           training_loss = 0.000416, testing_loss = 0.004931\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 208: training_accuracy = 0.9890, testing_accuracy = 0.9023\n",
            "           training_loss = 0.000317, testing_loss = 0.004834\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 209: training_accuracy = 0.9898, testing_accuracy = 0.9038\n",
            "           training_loss = 0.000316, testing_loss = 0.004858\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 210: training_accuracy = 0.9895, testing_accuracy = 0.9016\n",
            "           training_loss = 0.000325, testing_loss = 0.004858\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 211: training_accuracy = 0.9886, testing_accuracy = 0.8996\n",
            "           training_loss = 0.000337, testing_loss = 0.004966\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 212: training_accuracy = 0.9858, testing_accuracy = 0.8972\n",
            "           training_loss = 0.000414, testing_loss = 0.004924\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 213: training_accuracy = 0.9884, testing_accuracy = 0.9013\n",
            "           training_loss = 0.000336, testing_loss = 0.005069\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 214: training_accuracy = 0.9877, testing_accuracy = 0.8995\n",
            "           training_loss = 0.000357, testing_loss = 0.004896\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 215: training_accuracy = 0.9889, testing_accuracy = 0.9000\n",
            "           training_loss = 0.000333, testing_loss = 0.004746\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 216: training_accuracy = 0.9834, testing_accuracy = 0.8990\n",
            "           training_loss = 0.000469, testing_loss = 0.005257\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 217: training_accuracy = 0.9869, testing_accuracy = 0.9019\n",
            "           training_loss = 0.000372, testing_loss = 0.004969\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 218: training_accuracy = 0.9887, testing_accuracy = 0.9022\n",
            "           training_loss = 0.000335, testing_loss = 0.005233\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 219: training_accuracy = 0.9889, testing_accuracy = 0.8995\n",
            "           training_loss = 0.000330, testing_loss = 0.005006\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 220: training_accuracy = 0.9893, testing_accuracy = 0.9013\n",
            "           training_loss = 0.000316, testing_loss = 0.005193\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 221: training_accuracy = 0.9864, testing_accuracy = 0.8955\n",
            "           training_loss = 0.000389, testing_loss = 0.005191\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 222: training_accuracy = 0.9898, testing_accuracy = 0.9034\n",
            "           training_loss = 0.000310, testing_loss = 0.005000\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 223: training_accuracy = 0.9872, testing_accuracy = 0.8988\n",
            "           training_loss = 0.000363, testing_loss = 0.004952\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 224: training_accuracy = 0.9878, testing_accuracy = 0.9029\n",
            "           training_loss = 0.000347, testing_loss = 0.004798\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 225: training_accuracy = 0.9850, testing_accuracy = 0.8978\n",
            "           training_loss = 0.000425, testing_loss = 0.004766\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 226: training_accuracy = 0.9881, testing_accuracy = 0.9024\n",
            "           training_loss = 0.000345, testing_loss = 0.005028\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 227: training_accuracy = 0.9890, testing_accuracy = 0.8996\n",
            "           training_loss = 0.000308, testing_loss = 0.005013\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 228: training_accuracy = 0.9895, testing_accuracy = 0.9018\n",
            "           training_loss = 0.000307, testing_loss = 0.005038\n",
            "Learning Rate = 0.01000000\n",
            "Epoch 229: training_accuracy = 0.9868, testing_accuracy = 0.9009\n",
            "           training_loss = 0.000370, testing_loss = 0.004847\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 230: training_accuracy = 0.9889, testing_accuracy = 0.9000\n",
            "           training_loss = 0.000331, testing_loss = 0.005015\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 231: training_accuracy = 0.9950, testing_accuracy = 0.9025\n",
            "           training_loss = 0.000167, testing_loss = 0.004752\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 232: training_accuracy = 0.9950, testing_accuracy = 0.9027\n",
            "           training_loss = 0.000157, testing_loss = 0.004813\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 233: training_accuracy = 0.9959, testing_accuracy = 0.9039\n",
            "           training_loss = 0.000142, testing_loss = 0.004799\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 234: training_accuracy = 0.9961, testing_accuracy = 0.9039\n",
            "           training_loss = 0.000134, testing_loss = 0.004874\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 235: training_accuracy = 0.9964, testing_accuracy = 0.9044\n",
            "           training_loss = 0.000127, testing_loss = 0.004873\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 236: training_accuracy = 0.9963, testing_accuracy = 0.9053\n",
            "           training_loss = 0.000127, testing_loss = 0.004943\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 237: training_accuracy = 0.9960, testing_accuracy = 0.9049\n",
            "           training_loss = 0.000123, testing_loss = 0.005015\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 238: training_accuracy = 0.9972, testing_accuracy = 0.9040\n",
            "           training_loss = 0.000108, testing_loss = 0.005072\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 239: training_accuracy = 0.9966, testing_accuracy = 0.9049\n",
            "           training_loss = 0.000116, testing_loss = 0.005098\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 240: training_accuracy = 0.9968, testing_accuracy = 0.9048\n",
            "           training_loss = 0.000112, testing_loss = 0.005133\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 241: training_accuracy = 0.9966, testing_accuracy = 0.9042\n",
            "           training_loss = 0.000118, testing_loss = 0.005165\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 242: training_accuracy = 0.9969, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000111, testing_loss = 0.005206\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 243: training_accuracy = 0.9965, testing_accuracy = 0.9053\n",
            "           training_loss = 0.000111, testing_loss = 0.005238\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 244: training_accuracy = 0.9974, testing_accuracy = 0.9043\n",
            "           training_loss = 0.000101, testing_loss = 0.005271\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 245: training_accuracy = 0.9970, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000105, testing_loss = 0.005303\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 246: training_accuracy = 0.9974, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000096, testing_loss = 0.005280\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 247: training_accuracy = 0.9969, testing_accuracy = 0.9049\n",
            "           training_loss = 0.000106, testing_loss = 0.005285\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 248: training_accuracy = 0.9972, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000101, testing_loss = 0.005264\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 249: training_accuracy = 0.9975, testing_accuracy = 0.9053\n",
            "           training_loss = 0.000089, testing_loss = 0.005333\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 250: training_accuracy = 0.9973, testing_accuracy = 0.9051\n",
            "           training_loss = 0.000097, testing_loss = 0.005357\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 251: training_accuracy = 0.9974, testing_accuracy = 0.9050\n",
            "           training_loss = 0.000088, testing_loss = 0.005397\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 252: training_accuracy = 0.9975, testing_accuracy = 0.9065\n",
            "           training_loss = 0.000090, testing_loss = 0.005352\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 253: training_accuracy = 0.9975, testing_accuracy = 0.9056\n",
            "           training_loss = 0.000086, testing_loss = 0.005438\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 254: training_accuracy = 0.9973, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000093, testing_loss = 0.005415\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 255: training_accuracy = 0.9976, testing_accuracy = 0.9063\n",
            "           training_loss = 0.000091, testing_loss = 0.005462\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 256: training_accuracy = 0.9973, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000090, testing_loss = 0.005435\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 257: training_accuracy = 0.9976, testing_accuracy = 0.9064\n",
            "           training_loss = 0.000086, testing_loss = 0.005448\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 258: training_accuracy = 0.9976, testing_accuracy = 0.9060\n",
            "           training_loss = 0.000083, testing_loss = 0.005485\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 259: training_accuracy = 0.9977, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000086, testing_loss = 0.005527\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 260: training_accuracy = 0.9980, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000079, testing_loss = 0.005522\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 261: training_accuracy = 0.9977, testing_accuracy = 0.9064\n",
            "           training_loss = 0.000090, testing_loss = 0.005554\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 262: training_accuracy = 0.9975, testing_accuracy = 0.9065\n",
            "           training_loss = 0.000089, testing_loss = 0.005547\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 263: training_accuracy = 0.9974, testing_accuracy = 0.9050\n",
            "           training_loss = 0.000084, testing_loss = 0.005615\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 264: training_accuracy = 0.9977, testing_accuracy = 0.9048\n",
            "           training_loss = 0.000084, testing_loss = 0.005634\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 265: training_accuracy = 0.9977, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000085, testing_loss = 0.005640\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 266: training_accuracy = 0.9976, testing_accuracy = 0.9065\n",
            "           training_loss = 0.000085, testing_loss = 0.005583\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 267: training_accuracy = 0.9978, testing_accuracy = 0.9061\n",
            "           training_loss = 0.000079, testing_loss = 0.005657\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 268: training_accuracy = 0.9976, testing_accuracy = 0.9064\n",
            "           training_loss = 0.000081, testing_loss = 0.005648\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 269: training_accuracy = 0.9978, testing_accuracy = 0.9067\n",
            "           training_loss = 0.000081, testing_loss = 0.005694\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 270: training_accuracy = 0.9976, testing_accuracy = 0.9070\n",
            "           training_loss = 0.000085, testing_loss = 0.005692\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 271: training_accuracy = 0.9978, testing_accuracy = 0.9056\n",
            "           training_loss = 0.000079, testing_loss = 0.005679\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 272: training_accuracy = 0.9981, testing_accuracy = 0.9071\n",
            "           training_loss = 0.000074, testing_loss = 0.005704\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 273: training_accuracy = 0.9980, testing_accuracy = 0.9063\n",
            "           training_loss = 0.000075, testing_loss = 0.005733\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 274: training_accuracy = 0.9980, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000079, testing_loss = 0.005759\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 275: training_accuracy = 0.9979, testing_accuracy = 0.9051\n",
            "           training_loss = 0.000078, testing_loss = 0.005763\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 276: training_accuracy = 0.9978, testing_accuracy = 0.9056\n",
            "           training_loss = 0.000081, testing_loss = 0.005694\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 277: training_accuracy = 0.9979, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000073, testing_loss = 0.005750\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 278: training_accuracy = 0.9976, testing_accuracy = 0.9051\n",
            "           training_loss = 0.000082, testing_loss = 0.005752\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 279: training_accuracy = 0.9978, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000075, testing_loss = 0.005734\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 280: training_accuracy = 0.9974, testing_accuracy = 0.9062\n",
            "           training_loss = 0.000086, testing_loss = 0.005782\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 281: training_accuracy = 0.9976, testing_accuracy = 0.9064\n",
            "           training_loss = 0.000077, testing_loss = 0.005792\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 282: training_accuracy = 0.9982, testing_accuracy = 0.9050\n",
            "           training_loss = 0.000074, testing_loss = 0.005797\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 283: training_accuracy = 0.9979, testing_accuracy = 0.9062\n",
            "           training_loss = 0.000077, testing_loss = 0.005782\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 284: training_accuracy = 0.9982, testing_accuracy = 0.9060\n",
            "           training_loss = 0.000069, testing_loss = 0.005819\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 285: training_accuracy = 0.9978, testing_accuracy = 0.9064\n",
            "           training_loss = 0.000079, testing_loss = 0.005837\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 286: training_accuracy = 0.9979, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000078, testing_loss = 0.005813\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 287: training_accuracy = 0.9980, testing_accuracy = 0.9067\n",
            "           training_loss = 0.000075, testing_loss = 0.005816\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 288: training_accuracy = 0.9980, testing_accuracy = 0.9050\n",
            "           training_loss = 0.000072, testing_loss = 0.005885\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 289: training_accuracy = 0.9977, testing_accuracy = 0.9062\n",
            "           training_loss = 0.000083, testing_loss = 0.005900\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 290: training_accuracy = 0.9979, testing_accuracy = 0.9053\n",
            "           training_loss = 0.000075, testing_loss = 0.005919\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 291: training_accuracy = 0.9977, testing_accuracy = 0.9064\n",
            "           training_loss = 0.000080, testing_loss = 0.005882\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 292: training_accuracy = 0.9982, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000068, testing_loss = 0.005884\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 293: training_accuracy = 0.9981, testing_accuracy = 0.9049\n",
            "           training_loss = 0.000072, testing_loss = 0.005927\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 294: training_accuracy = 0.9980, testing_accuracy = 0.9052\n",
            "           training_loss = 0.000075, testing_loss = 0.005930\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 295: training_accuracy = 0.9979, testing_accuracy = 0.9056\n",
            "           training_loss = 0.000074, testing_loss = 0.005904\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 296: training_accuracy = 0.9980, testing_accuracy = 0.9067\n",
            "           training_loss = 0.000075, testing_loss = 0.005848\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 297: training_accuracy = 0.9981, testing_accuracy = 0.9062\n",
            "           training_loss = 0.000068, testing_loss = 0.005913\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 298: training_accuracy = 0.9980, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000073, testing_loss = 0.005933\n",
            "Learning Rate = 0.00100000\n",
            "Epoch 299: training_accuracy = 0.9980, testing_accuracy = 0.9064\n",
            "           training_loss = 0.000070, testing_loss = 0.005939\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 300: training_accuracy = 0.9980, testing_accuracy = 0.9065\n",
            "           training_loss = 0.000073, testing_loss = 0.005905\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 301: training_accuracy = 0.9981, testing_accuracy = 0.9066\n",
            "           training_loss = 0.000070, testing_loss = 0.005886\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 302: training_accuracy = 0.9984, testing_accuracy = 0.9064\n",
            "           training_loss = 0.000064, testing_loss = 0.005885\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 303: training_accuracy = 0.9980, testing_accuracy = 0.9063\n",
            "           training_loss = 0.000070, testing_loss = 0.005880\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 304: training_accuracy = 0.9981, testing_accuracy = 0.9063\n",
            "           training_loss = 0.000066, testing_loss = 0.005890\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 305: training_accuracy = 0.9980, testing_accuracy = 0.9069\n",
            "           training_loss = 0.000072, testing_loss = 0.005892\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 306: training_accuracy = 0.9981, testing_accuracy = 0.9062\n",
            "           training_loss = 0.000068, testing_loss = 0.005899\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 307: training_accuracy = 0.9983, testing_accuracy = 0.9056\n",
            "           training_loss = 0.000063, testing_loss = 0.005901\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 308: training_accuracy = 0.9983, testing_accuracy = 0.9053\n",
            "           training_loss = 0.000066, testing_loss = 0.005898\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 309: training_accuracy = 0.9985, testing_accuracy = 0.9066\n",
            "           training_loss = 0.000061, testing_loss = 0.005892\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 310: training_accuracy = 0.9984, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000061, testing_loss = 0.005902\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 311: training_accuracy = 0.9984, testing_accuracy = 0.9066\n",
            "           training_loss = 0.000062, testing_loss = 0.005908\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 312: training_accuracy = 0.9984, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000064, testing_loss = 0.005915\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 313: training_accuracy = 0.9983, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000067, testing_loss = 0.005916\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 314: training_accuracy = 0.9982, testing_accuracy = 0.9052\n",
            "           training_loss = 0.000064, testing_loss = 0.005913\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 315: training_accuracy = 0.9984, testing_accuracy = 0.9051\n",
            "           training_loss = 0.000064, testing_loss = 0.005923\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 316: training_accuracy = 0.9983, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000065, testing_loss = 0.005916\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 317: training_accuracy = 0.9987, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000058, testing_loss = 0.005921\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 318: training_accuracy = 0.9984, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000063, testing_loss = 0.005915\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 319: training_accuracy = 0.9986, testing_accuracy = 0.9053\n",
            "           training_loss = 0.000060, testing_loss = 0.005918\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 320: training_accuracy = 0.9986, testing_accuracy = 0.9053\n",
            "           training_loss = 0.000058, testing_loss = 0.005908\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 321: training_accuracy = 0.9982, testing_accuracy = 0.9060\n",
            "           training_loss = 0.000071, testing_loss = 0.005900\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 322: training_accuracy = 0.9979, testing_accuracy = 0.9050\n",
            "           training_loss = 0.000067, testing_loss = 0.005911\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 323: training_accuracy = 0.9983, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000062, testing_loss = 0.005904\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 324: training_accuracy = 0.9988, testing_accuracy = 0.9050\n",
            "           training_loss = 0.000059, testing_loss = 0.005906\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 325: training_accuracy = 0.9987, testing_accuracy = 0.9061\n",
            "           training_loss = 0.000060, testing_loss = 0.005907\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 326: training_accuracy = 0.9982, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000062, testing_loss = 0.005925\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 327: training_accuracy = 0.9985, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000059, testing_loss = 0.005922\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 328: training_accuracy = 0.9982, testing_accuracy = 0.9052\n",
            "           training_loss = 0.000066, testing_loss = 0.005917\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 329: training_accuracy = 0.9984, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000068, testing_loss = 0.005923\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 330: training_accuracy = 0.9985, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000062, testing_loss = 0.005932\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 331: training_accuracy = 0.9982, testing_accuracy = 0.9053\n",
            "           training_loss = 0.000062, testing_loss = 0.005927\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 332: training_accuracy = 0.9981, testing_accuracy = 0.9048\n",
            "           training_loss = 0.000064, testing_loss = 0.005931\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 333: training_accuracy = 0.9984, testing_accuracy = 0.9048\n",
            "           training_loss = 0.000064, testing_loss = 0.005937\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 334: training_accuracy = 0.9983, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000062, testing_loss = 0.005928\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 335: training_accuracy = 0.9986, testing_accuracy = 0.9049\n",
            "           training_loss = 0.000059, testing_loss = 0.005938\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 336: training_accuracy = 0.9986, testing_accuracy = 0.9051\n",
            "           training_loss = 0.000057, testing_loss = 0.005928\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 337: training_accuracy = 0.9986, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000059, testing_loss = 0.005933\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 338: training_accuracy = 0.9987, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000060, testing_loss = 0.005940\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 339: training_accuracy = 0.9983, testing_accuracy = 0.9061\n",
            "           training_loss = 0.000066, testing_loss = 0.005943\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 340: training_accuracy = 0.9987, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000057, testing_loss = 0.005936\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 341: training_accuracy = 0.9985, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000061, testing_loss = 0.005938\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 342: training_accuracy = 0.9984, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000061, testing_loss = 0.005934\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 343: training_accuracy = 0.9981, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000070, testing_loss = 0.005933\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 344: training_accuracy = 0.9982, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000064, testing_loss = 0.005935\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 345: training_accuracy = 0.9984, testing_accuracy = 0.9060\n",
            "           training_loss = 0.000062, testing_loss = 0.005934\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 346: training_accuracy = 0.9983, testing_accuracy = 0.9060\n",
            "           training_loss = 0.000062, testing_loss = 0.005938\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 347: training_accuracy = 0.9983, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000060, testing_loss = 0.005942\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 348: training_accuracy = 0.9983, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000064, testing_loss = 0.005957\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 349: training_accuracy = 0.9987, testing_accuracy = 0.9051\n",
            "           training_loss = 0.000055, testing_loss = 0.005965\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 350: training_accuracy = 0.9988, testing_accuracy = 0.9060\n",
            "           training_loss = 0.000059, testing_loss = 0.005955\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 351: training_accuracy = 0.9986, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000061, testing_loss = 0.005956\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 352: training_accuracy = 0.9986, testing_accuracy = 0.9052\n",
            "           training_loss = 0.000057, testing_loss = 0.005963\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 353: training_accuracy = 0.9985, testing_accuracy = 0.9060\n",
            "           training_loss = 0.000062, testing_loss = 0.005954\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 354: training_accuracy = 0.9986, testing_accuracy = 0.9056\n",
            "           training_loss = 0.000061, testing_loss = 0.005945\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 355: training_accuracy = 0.9985, testing_accuracy = 0.9046\n",
            "           training_loss = 0.000064, testing_loss = 0.005953\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 356: training_accuracy = 0.9985, testing_accuracy = 0.9051\n",
            "           training_loss = 0.000059, testing_loss = 0.005955\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 357: training_accuracy = 0.9987, testing_accuracy = 0.9051\n",
            "           training_loss = 0.000057, testing_loss = 0.005958\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 358: training_accuracy = 0.9982, testing_accuracy = 0.9048\n",
            "           training_loss = 0.000069, testing_loss = 0.005963\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 359: training_accuracy = 0.9983, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000061, testing_loss = 0.005963\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 360: training_accuracy = 0.9984, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000063, testing_loss = 0.005973\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 361: training_accuracy = 0.9984, testing_accuracy = 0.9056\n",
            "           training_loss = 0.000063, testing_loss = 0.005972\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 362: training_accuracy = 0.9986, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000055, testing_loss = 0.005967\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 363: training_accuracy = 0.9988, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000059, testing_loss = 0.005971\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 364: training_accuracy = 0.9986, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000061, testing_loss = 0.005976\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 365: training_accuracy = 0.9983, testing_accuracy = 0.9056\n",
            "           training_loss = 0.000064, testing_loss = 0.005982\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 366: training_accuracy = 0.9989, testing_accuracy = 0.9062\n",
            "           training_loss = 0.000055, testing_loss = 0.005971\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 367: training_accuracy = 0.9985, testing_accuracy = 0.9053\n",
            "           training_loss = 0.000058, testing_loss = 0.005965\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 368: training_accuracy = 0.9983, testing_accuracy = 0.9047\n",
            "           training_loss = 0.000064, testing_loss = 0.005968\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 369: training_accuracy = 0.9986, testing_accuracy = 0.9061\n",
            "           training_loss = 0.000062, testing_loss = 0.005954\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 370: training_accuracy = 0.9984, testing_accuracy = 0.9062\n",
            "           training_loss = 0.000061, testing_loss = 0.005971\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 371: training_accuracy = 0.9984, testing_accuracy = 0.9066\n",
            "           training_loss = 0.000061, testing_loss = 0.005969\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 372: training_accuracy = 0.9983, testing_accuracy = 0.9060\n",
            "           training_loss = 0.000068, testing_loss = 0.005974\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 373: training_accuracy = 0.9987, testing_accuracy = 0.9048\n",
            "           training_loss = 0.000056, testing_loss = 0.005971\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 374: training_accuracy = 0.9981, testing_accuracy = 0.9061\n",
            "           training_loss = 0.000064, testing_loss = 0.005975\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 375: training_accuracy = 0.9986, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000059, testing_loss = 0.005982\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 376: training_accuracy = 0.9983, testing_accuracy = 0.9061\n",
            "           training_loss = 0.000065, testing_loss = 0.005986\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 377: training_accuracy = 0.9985, testing_accuracy = 0.9061\n",
            "           training_loss = 0.000060, testing_loss = 0.005981\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 378: training_accuracy = 0.9985, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000062, testing_loss = 0.005985\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 379: training_accuracy = 0.9988, testing_accuracy = 0.9062\n",
            "           training_loss = 0.000057, testing_loss = 0.005986\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 380: training_accuracy = 0.9983, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000061, testing_loss = 0.005977\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 381: training_accuracy = 0.9986, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000060, testing_loss = 0.005979\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 382: training_accuracy = 0.9984, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000065, testing_loss = 0.005993\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 383: training_accuracy = 0.9987, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000056, testing_loss = 0.005993\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 384: training_accuracy = 0.9984, testing_accuracy = 0.9059\n",
            "           training_loss = 0.000065, testing_loss = 0.005990\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 385: training_accuracy = 0.9985, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000060, testing_loss = 0.005987\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 386: training_accuracy = 0.9985, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000061, testing_loss = 0.005989\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 387: training_accuracy = 0.9983, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000067, testing_loss = 0.005995\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 388: training_accuracy = 0.9988, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000056, testing_loss = 0.005997\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 389: training_accuracy = 0.9986, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000058, testing_loss = 0.005987\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 390: training_accuracy = 0.9985, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000058, testing_loss = 0.005991\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 391: training_accuracy = 0.9988, testing_accuracy = 0.9056\n",
            "           training_loss = 0.000059, testing_loss = 0.005995\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 392: training_accuracy = 0.9984, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000061, testing_loss = 0.006002\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 393: training_accuracy = 0.9983, testing_accuracy = 0.9057\n",
            "           training_loss = 0.000060, testing_loss = 0.006003\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 394: training_accuracy = 0.9983, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000062, testing_loss = 0.005999\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 395: training_accuracy = 0.9985, testing_accuracy = 0.9051\n",
            "           training_loss = 0.000058, testing_loss = 0.006000\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 396: training_accuracy = 0.9981, testing_accuracy = 0.9064\n",
            "           training_loss = 0.000067, testing_loss = 0.005998\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 397: training_accuracy = 0.9987, testing_accuracy = 0.9061\n",
            "           training_loss = 0.000058, testing_loss = 0.005996\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 398: training_accuracy = 0.9986, testing_accuracy = 0.9054\n",
            "           training_loss = 0.000058, testing_loss = 0.005995\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 399: training_accuracy = 0.9988, testing_accuracy = 0.9055\n",
            "           training_loss = 0.000055, testing_loss = 0.006003\n",
            "Learning Rate = 0.00010000\n",
            "Epoch 400: training_accuracy = 0.9985, testing_accuracy = 0.9058\n",
            "           training_loss = 0.000063, testing_loss = 0.006006\n",
            "Finished Training after 400 iterations\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}